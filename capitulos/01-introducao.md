# 01 - Introdução

[← Voltar ao Sumário](00-sumario.md)

---

Um **prompt** é a entrada que um modelo de linguagem grande (LLM) usa para prever uma saída específica.

> Você não precisa ser cientista de dados ou engenheiro de ML — **qualquer pessoa pode escrever um prompt**.

No entanto, criar prompts eficazes requer prática. Muitos aspectos afetam a qualidade da resposta:

- O modelo escolhido (GPT, Claude, Gemini, LLaMA, etc.)
- As configurações do modelo (temperatura, top-K, top-P)
- A escolha de palavras, estilo e tom
- A estrutura e o contexto fornecido

## O que é Engenharia de Prompt?

> **Engenharia de Prompt** é o processo iterativo de projetar entradas de alta qualidade que guiam LLMs a produzir saídas precisas e úteis.

Prompts inadequados podem levar a:
- ❌ Respostas ambíguas
- ❌ Informações imprecisas
- ❌ Formatos incorretos
- ❌ Desperdício de tokens/custo

## Este Guia Vai Te Ajudar a:

✅ Entender como LLMs funcionam "por baixo do capô"  
✅ Dominar as principais técnicas de prompting  
✅ Escolher as configurações certas para cada tarefa  
✅ Evitar armadilhas comuns  
✅ Criar prompts robustos e reutilizáveis  

## Próximos Passos

- [Como LLMs Funcionam](02-como-llms-funcionam.md) - Entenda o básico
- [Configurações de Saída](03-configuracoes.md) - Ajuste temperatura e sampling
- [Técnicas de Prompting](tecnicas/01-zero-shot.md) - Comece com Zero-shot
