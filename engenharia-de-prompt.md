# üéØ Engenharia de Prompt - Guia Completo

**Autor original:** Lee Boonstra (Google)  
**Vers√£o:** 2.0 | **Atualiza√ß√£o:** Fevereiro 2025  
**Idioma:** Portugu√™s (Brasil)

---

## üìë √çndice

1. [Introdu√ß√£o](#introdu√ß√£o)
2. [Como LLMs Funcionam](#como-llms-funcionam)
3. [Configura√ß√µes de Sa√≠da](#configura√ß√µes-de-sa√≠da)
   - [Comprimento da Sa√≠da](#comprimento-da-sa√≠da)
   - [Temperatura](#temperatura)
   - [Top-K e Top-P](#top-k-e-top-p)
   - [Guia R√°pido de Configura√ß√µes](#guia-r√°pido-de-configura√ß√µes)
4. [T√©cnicas de Prompting](#t√©cnicas-de-prompting)
   - [Zero-shot](#1-zero-shot)
   - [One-shot e Few-shot](#2-one-shot-e-few-shot)
   - [Prompt de Sistema](#3-prompt-de-sistema)
   - [Prompt de Papel (Role)](#4-prompt-de-papel-role)
   - [Prompt Contextual](#5-prompt-contextual)
   - [Step-back (Recuo)](#6-step-back-recuo)
   - [Cadeia de Pensamento (CoT)](#7-cadeia-de-pensamento-cot)
   - [Auto-consist√™ncia](#8-auto-consist√™ncia)
   - [√Årvore de Pensamentos (ToT)](#9-√°rvore-de-pensamentos-tot)
   - [ReAct (Raciocinar e Agir)](#10-react-raciocinar-e-agir)
5. [Prompting para C√≥digo](#prompting-para-c√≥digo)
6. [Engenharia Autom√°tica de Prompts](#engenharia-autom√°tica-de-prompts-ape)
7. [Melhores Pr√°ticas](#melhores-pr√°ticas)
8. [Anti-Padr√µes](#anti-padr√µes--o-que-evitar)
9. [Checklist de Revis√£o](#checklist-de-revis√£o-de-prompt)
10. [Templates Prontos](#templates-prontos-para-usar)
11. [Troubleshooting](#troubleshooting-comum)
12. [Refer√™ncia R√°pida](#refer√™ncia-r√°pida)

---

## Introdu√ß√£o

Um **prompt** √© a entrada que um modelo de linguagem grande (LLM) usa para prever uma sa√≠da espec√≠fica. Voc√™ n√£o precisa ser cientista de dados ou engenheiro de ML ‚Äî **qualquer pessoa pode escrever um prompt**.

No entanto, criar prompts eficazes requer pr√°tica. Muitos aspectos afetam a qualidade da resposta:

- O modelo escolhido (GPT, Claude, Gemini, LLaMA, etc.)
- As configura√ß√µes do modelo (temperatura, top-K, top-P)
- A escolha de palavras, estilo e tom
- A estrutura e o contexto fornecido

> **Engenharia de Prompt** √© o processo iterativo de projetar entradas de alta qualidade que guiam LLMs a produzir sa√≠das precisas e √∫teis.

### Este Guia Vai Te Ajudar a:

‚úÖ Entender como LLMs funcionam "por baixo do cap√¥"  
‚úÖ Dominar as principais t√©cnicas de prompting  
‚úÖ Escolher as configura√ß√µes certas para cada tarefa  
‚úÖ Evitar armadilhas comuns  
‚úÖ Criar prompts robustos e reutiliz√°veis  

---

## Como LLMs Funcionam

LLMs s√£o **mecanismos de previs√£o de tokens**:

1. Recebem texto sequencial como entrada
2. Preveem qual deve ser o pr√≥ximo token (baseado em treinamento)
3. Adicionam o token previsto ao final do texto
4. Repetem o processo

A previs√£o √© baseada na rela√ß√£o entre tokens anteriores e o que o LLM viu durante treinamento.

### O Que Isso Significa na Pr√°tica?

| Conceito | Implica√ß√£o |
|----------|------------|
| **Previs√£o probabil√≠stica** | O modelo n√£o "pensa" ‚Äî prev√™ o mais prov√°vel |
| **Contexto importa** | Tokens anteriores influenciam os pr√≥ximos |
| **Treinamento define limites** | O modelo s√≥ sabe o que viu no treinamento |
| **Sem mem√≥ria entre sess√µes** | Cada conversa come√ßa do zero |

---

## Configura√ß√µes de Sa√≠da

### Comprimento da Sa√≠da

Controla quantos tokens o modelo pode gerar.

> ‚ö†Ô∏è **Importante:** Reduzir o limite N√ÉO faz o modelo mais sucinto ‚Äî apenas corta a resposta quando atinge o limite. Se precisar de respostas curtas, **ajuste tamb√©m o prompt**.

**Quando ajustar:**
- APIs com custo por token ‚Üí limite menor
- Tarefas longas (relat√≥rios, c√≥digo) ‚Üí limite maior
- ReAct/agentes ‚Üí limite generoso (evita cortes em cadeias de racioc√≠nio)

---

### Temperatura

Controla a **aleatoriedade** na sele√ß√£o de tokens.

| Valor | Comportamento | Uso Ideal |
|-------|---------------|-----------|
| **0** | Determin√≠stico (sempre o token mais prov√°vel) | C√≥digo, matem√°tica, fatos |
| **0.1 - 0.3** | Baixa varia√ß√£o | Classifica√ß√£o, extra√ß√£o, resumo |
| **0.4 - 0.7** | Equilibrado | Conversa√ß√£o, escrita geral |
| **0.8 - 1.0** | Alta varia√ß√£o | Criatividade, brainstorming |
| **> 1.0** | Muito aleat√≥rio | Experimental, surpreendente |

**Analogia:** Temperatura √© como a "temperatura softmax" em ML:
- Baixa = alta certeza, poucas op√ß√µes consideradas
- Alta = mais incerteza, mais op√ß√µes consideradas

---

### Top-K e Top-P

Restringem quais tokens s√£o candidatos a serem selecionados.

#### Top-K
Seleciona apenas os **K tokens mais prov√°veis**.

- **Top-K = 1**: Sempre o mais prov√°vel (decodifica√ß√£o gananciosa)
- **Top-K = 40**: Considera os 40 mais prov√°veis
- **Top-K alto** (100+): Praticamente sem restri√ß√£o

#### Top-P (Amostragem Nuclear)
Seleciona tokens at√© atingir **probabilidade acumulada P**.

- **Top-P = 0.1**: Muito restritivo
- **Top-P = 0.9**: Padr√£o comum
- **Top-P = 1.0**: Sem restri√ß√£o

---

### Guia R√°pido de Configura√ß√µes

| Cen√°rio | Temperatura | Top-P | Top-K | Max Tokens |
|---------|-------------|-------|-------|------------|
| **C√≥digo/Debug** | 0 | 0.9 | 20 | 2000 |
| **Matem√°tica/L√≥gica** | 0 | 0.9 | 20 | 500 |
| **Classifica√ß√£o** | 0.1 | 0.9 | 20 | 100 |
| **Resumo** | 0.2 | 0.95 | 30 | 500 |
| **Conversa√ß√£o** | 0.5 | 0.95 | 40 | 1000 |
| **Escrita Criativa** | 0.8 | 0.99 | 50 | 2000 |
| **Brainstorming** | 0.9 | 0.99 | 60 | 1500 |

> üîß **Dica:** Se temperatura = 0, Top-K e Top-P s√£o ignorados. Se Top-K = 1, temperatura √© ignorada.

---

## T√©cnicas de Prompting

### 1. Zero-shot

O prompt mais simples: **sem exemplos**, apenas a instru√ß√£o.

**Estrutura:**
```
[Instru√ß√£o clara]
[Contexto/dados de entrada]
[Formato esperado da sa√≠da]
```

**Exemplo - Classifica√ß√£o:**

```
Classifique a avalia√ß√£o abaixo como POSITIVO, NEGATIVO ou NEUTRO.

Avalia√ß√£o: "O produto chegou antes do prazo, mas a qualidade deixou a desejar."

Classifica√ß√£o:
```

**Sa√≠da:** `NEUTRO`

**Quando usar:**
- ‚úÖ Tarefas simples e bem definidas
- ‚úÖ Modelo j√° treinado para o tipo de tarefa
- ‚úÖ Poucos tokens dispon√≠veis

**Quando evitar:**
- ‚ùå Tarefas complexas ou amb√≠guas
- ‚ùå Formato de sa√≠da espec√≠fico necess√°rio
- ‚ùå Modelo menos capaz ou desconhecido

---

### 2. One-shot e Few-shot

Fornece **exemplos** para o modelo imitar o padr√£o.

**One-shot** = 1 exemplo  
**Few-shot** = 3-5 exemplos (recomendado)

**Estrutura:**
```
[Instru√ß√£o]

EXEMPLO 1:
Entrada: [exemplo de entrada]
Sa√≠da: [exemplo de sa√≠da]

EXEMPLO 2:
Entrada: [exemplo de entrada]
Sa√≠da: [exemplo de sa√≠da]

EXEMPLO 3:
Entrada: [exemplo de entrada]
Sa√≠da: [exemplo de sa√≠da]

Agora fa√ßa:
Entrada: [entrada real]
Sa√≠da:
```

**Exemplo - Extra√ß√£o de Entidades:**

```
Extraia nomes de pessoas e locais do texto.

EXEMPLO 1:
Texto: "Maria foi a Paris visitar o Louvre."
Sa√≠da: {"pessoas": ["Maria"], "locais": ["Paris", "Louvre"]}

EXEMPLO 2:
Texto: "Jo√£o e Ana se encontraram no caf√© central de S√£o Paulo."
Sa√≠da: {"pessoas": ["Jo√£o", "Ana"], "locais": ["S√£o Paulo", "caf√© central"]}

Texto: "Carlos viajou de Bras√≠lia para Rio de Janeiro com sua esposa."
Sa√≠da:
```

**Sa√≠da:**
```json
{"pessoas": ["Carlos"], "locais": ["Bras√≠lia", "Rio de Janeiro"]}
```

> üí° **Dicas para Few-shot:**
> - Use **3-5 exemplos** (mais que isso raramente ajuda)
> - **Misture as classes** em tarefas de classifica√ß√£o (evite vi√©s)
> - Inclua **casos extremos** (edge cases)
> - Exemplos devem ser **diversos** mas **consistentes** no formato
> - **Evite exemplos ruins** ‚Äî o modelo copiar√° os erros

---

### 3. Prompt de Sistema

Define o **comportamento global** do modelo. Ideal para instru√ß√µes que se aplicam a toda a conversa.

**Estrutura:**
```
[Identidade/Papel]
[Regras de comportamento]
[Formato de sa√≠da]
[Restri√ß√µes]
```

**Exemplo:**

```
Voc√™ √© um assistente especializado em an√°lise de contratos jur√≠dicos.

REGRAS:
- Identifique cl√°usulas de risco
- Destaque termos amb√≠guos
- Sugira melhorias de reda√ß√£o
- Use linguagem t√©cnica mas acess√≠vel

FORMATO DE SA√çDA:
Para cada ponto identificado:
1. **Cl√°usula**: [cita√ß√£o]
2. **Risco**: [baixo/m√©dio/alto]
3. **Explica√ß√£o**: [an√°lise]
4. **Sugest√£o**: [recomenda√ß√£o]

RESTRICOES:
- N√£o d√™ conselhos legais definitivos
- Sempre sugira consultar um advogado
```

**Benef√≠cios:**
- Consist√™ncia em conversas longas
- Define "regras do jogo" uma vez
- √ötil para chatbots e agentes

---

### 4. Prompt de Papel (Role)

Atribui uma **identidade/especialidade** ao modelo.

**T√©cnicas eficazes:**

| Papel | Quando Usar |
|-------|-------------|
| "Voc√™ √© um expert em [√°rea]" | Tarefas t√©cnicas |
| "Aja como um [profiss√£o]" | Tom espec√≠fico |
| "Imagine que voc√™ √© [pessoa]" | Perspectiva diferente |
| "Voc√™ tem 20 anos de experi√™ncia em [√°rea]" | Autoridade |

**Exemplos:**

```
# T√©cnico
Voc√™ √© um engenheiro de software s√™nior com 15 anos de experi√™ncia em Python e arquitetura de sistemas distribu√≠dos. Revise o c√≥digo abaixo focando em performance e escalabilidade.

# Criativo
Aja como um copywriter de propaganda premiada. Crie 5 headlines impactantes para um aplicativo de medita√ß√£o.

# Educacional
Voc√™ √© um professor de f√≠sica do ensino m√©dio. Explique relatividade para um estudante de 16 anos usando analogias do dia a dia.

# Cr√≠tico
Imagine que voc√™ √© um investidor conservador analisando este pitch de startup. Identifique 5 riscos principais.
```

**Estilos de tom:**
- Direto
- Formal
- Informal
- Humor√≠stico
- Inspiracional
- Persuasivo
- Descritivo
- Confrontacional
- Influente

---

### 5. Prompt Contextual

Fornece **informa√ß√µes espec√≠ficas** relevantes para a tarefa atual.

**Tipos de contexto:**

| Tipo | Exemplo |
|------|---------|
| **P√∫blico-alvo** | "Este texto √© para CEOs de startups" |
| **Restri√ß√µes** | "M√°ximo 280 caracteres" |
| **Prefer√™ncias** | "Prefira bullet points a par√°grafos" |
| **Antecedentes** | "O usu√°rio j√° tentou X e Y" |
| **Tom desejado** | "Tom profissional mas amig√°vel" |

**Exemplo:**

```
CONTEXTO:
- P√∫blico: Gerentes de projeto iniciantes
- Objetivo: Explicar metodologias √°geis
- Restri√ß√£o: M√°ximo 300 palavras
- Tom: Educativo e encorajador
- Formato: Compara√ß√£o em tabela

TAREFA:
Compare Scrum e Kanban para iniciantes.
```

---

### 6. Step-back (Recuo)

Faz uma **pergunta geral primeiro**, depois usa a resposta para a tarefa espec√≠fica.

**Processo:**
1. Pergunta geral/abstrata ‚Üí ativa conhecimento amplo
2. Resposta como contexto ‚Üí guia racioc√≠nio espec√≠fico

**Exemplo - Criando campanha de marketing:**

**Passo 1 (Recuo):**
```
Quais s√£o os 5 princ√≠pios fundamentais de uma campanha de marketing digital bem-sucedida para produtos SaaS B2B?
```

**Resposta:** (1) Proposta de valor clara, (2) Persona definida, (3) Funil estruturado, (4) Prova social, (5) CTA persuasivo

**Passo 2 (Espec√≠fico):**
```
Considerando esses 5 princ√≠pios:
[lista a resposta acima]

Crie uma campanha de marketing para um software de gest√£o de estoque para pequenos varejistas.
```

**Benef√≠cios:**
- Ativa conhecimento mais amplo
- Reduz vi√©s de detalhes espec√≠ficos
- Melhora qualidade do racioc√≠nio

---

### 7. Cadeia de Pensamento (CoT)

Faz o modelo **explicitar o racioc√≠nio** passo a passo.

**T√©cnicas de ativa√ß√£o:**

| T√©cnica | Exemplo |
|---------|---------|
| Frase m√°gica | "Vamos pensar passo a passo." |
| Instru√ß√£o direta | "Explique seu racioc√≠nio antes de responder." |
| Few-shot com CoT | Exemplos que mostram racioc√≠nio |

**Exemplo - Problema L√≥gico:**

‚ùå **Sem CoT:**
```
Um tanque tem 500L de √°gua. Uma torneira enche 30L/h, outra esvazia 10L/h. Quanto tempo para encher?
```
Sa√≠da: `25 horas` (errado)

‚úÖ **Com CoT:**
```
Um tanque tem 500L de √°gua. Uma torneira enche 30L/h, outra esvazia 10L/h. Quanto tempo para encher?

Vamos pensar passo a passo.
```

Sa√≠da:
```
1. Volume necess√°rio: 500L - 500L = 0L (j√° est√° cheio? Vou assumir que est√° vazio)
   Volume para encher: 500L

2. Taxa l√≠quida de enchimento:
   Entra: 30L/h
   Sai: 10L/h
   L√≠quido: 30 - 10 = 20L/h

3. Tempo = Volume / Taxa
   Tempo = 500L / 20L/h = 25 horas

Resposta: 25 horas
```

> üìù **Nota:** Neste caso a resposta est√° correta, mas sem CoT o modelo poderia ter pulado etapas.

**Quando usar CoT:**
- ‚úÖ Matem√°tica e l√≥gica
- ‚úÖ Problemas multi-passo
- ‚úÖ An√°lise complexa
- ‚úÖ Debugging de c√≥digo
- ‚úÖ Tomada de decis√£o

**Melhores Pr√°ticas CoT:**
- Combine com few-shot para tarefas complexas
- Use temperatura baixa (0-0.3)
- Pe√ßa explicitamente "pense alto"
- Monitore custo de tokens

---

### 8. Auto-consist√™ncia

Gera **m√∫ltiplas respostas** e escolhe a mais frequente (vota√ß√£o).

**Processo:**
1. Execute o mesmo prompt N vezes (temperatura alta)
2. Extraia a resposta de cada execu√ß√£o
3. Conte a frequ√™ncia de cada resposta
4. Retorne a mais comum

**Exemplo - Classifica√ß√£o Amb√≠gua:**

```
Email: "Ol√°, notei que seu site tem uma vulnerabilidade XSS interessante. 
N√£o se preocupe, n√£o vou explorar. S√≥ achei curioso. Abra√ßos, Hackerman."

Classifique como: IMPORTANTE ou N√ÉO IMPORTANTE.
```

**Execu√ß√£o 1:** IMPORTANTE (risco de seguran√ßa)  
**Execu√ß√£o 2:** N√ÉO IMPORTANTE (tom amig√°vel, sem amea√ßa)  
**Execu√ß√£o 3:** IMPORTANTE (vulnerabilidade real)  
**Execu√ß√£o 4:** IMPORTANTE (deve ser verificado)  
**Execu√ß√£o 5:** N√ÉO IMPORTANTE (parece teste amig√°vel)

**Resultado por vota√ß√£o:** IMPORTANTE (3/5)

> ‚ö†Ô∏è **Trade-off:** Alto custo (N√ó tokens) mas maior confian√ßa na resposta.

---

### 9. √Årvore de Pensamentos (ToT)

Explora **m√∫ltiplos caminhos de racioc√≠nio** em paralelo, ramificando como uma √°rvore.

**Diferen√ßa para CoT:**
- **CoT:** Uma cadeia linear de pensamentos
- **ToT:** M√∫ltiplas cadeias ramificadas, podendo voltar e tentar outro caminho

**Estrutura:**
```
              [Problema]
                 |
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      [Op√ß√£o A] [Op√ß√£o B] [Op√ß√£o C]
          |         |         |
      [A.1]     [B.1]     [C.1]
      [A.2]     [B.2]     [C.2]
          ‚Üì         ‚Üì         ‚Üì
      [Eval A]  [Eval B]  [Eval C]
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
            [Melhor Solu√ß√£o]
```

**Quando usar:**
- Problemas de otimiza√ß√£o
- Jogos e puzzles
- Planejamento complexo
- Decis√µes com m√∫ltiplas alternativas

---

### 10. ReAct (Raciocinar e Agir)

Combina **racioc√≠nio** com **uso de ferramentas** externas.

**Ciclo ReAct:**
1. **Thought** (Pensamento): O que preciso fazer?
2. **Action** (A√ß√£o): Qual ferramenta usar?
3. **Observation** (Observa√ß√£o): O que aconteceu?
4. Repete at√© completar

**Exemplo:**

```
Pergunta: Quantos filhos os membros do Metallica t√™m no total?

Thought: Preciso descobrir quem s√£o os membros da banda e quantos filhos cada um tem.

Action: Search[Membros do Metallica]
Observation: James Hetfield, Lars Ulrich, Kirk Hammett, Robert Trujillo

Thought: Agora preciso descobrir quantos filhos cada um tem.

Action: Search[Quantos filhos James Hetfield tem]
Observation: Tr√™s filhos: Cali, Castor e Marcella

Action: Search[Quantos filhos Lars Ulrich tem]
Observation: Tr√™s filhos

Action: Search[Quantos filhos Kirk Hammett tem]
Observation: Dois filhos: Angel e Vincenzo

Action: Search[Quantos filhos Robert Trujillo tem]
Observation: Dois filhos

Thought: Agora posso somar: 3 + 3 + 2 + 2 = 10

Answer: Os membros do Metallica t√™m 10 filhos no total.
```

**Ferramentas comuns em ReAct:**
- Busca web
- Calculadora
- Executor de c√≥digo
- APIs externas
- Banco de dados

---

## Prompting para C√≥digo

### Escrever C√≥digo

```
Escreva uma fun√ß√£o Python que [descri√ß√£o clara].

Requisitos:
- [Requisito 1]
- [Requisito 2]
- [Requisito 3]

Inclua:
- Docstring
- Type hints
- Tratamento de erros
- Exemplos de uso
```

### Explicar C√≥digo

```
Explique o c√≥digo abaixo para um desenvolvedor j√∫nior:

[c√≥digo]

Cubra:
1. O que o c√≥digo faz (vis√£o geral)
2. Como funciona (passo a passo)
3. Conceitos importantes utilizados
4. Poss√≠veis melhorias
```

### Traduzir C√≥digo

```
Traduza este c√≥digo de [linguagem A] para [linguagem B]:

[c√≥digo original]

Mantenha:
- A mesma l√≥gica
- Boas pr√°ticas da linguagem destino
- Coment√°rios relevantes
```

### Debugar C√≥digo

```
O c√≥digo abaixo est√° apresentando o seguinte erro:

[erro/stack trace]

C√≥digo:
[c√≥digo com bug]

Por favor:
1. Identifique a causa do erro
2. Explique por que acontece
3. Forne√ßa o c√≥digo corrigido
4. Sugira como evitar erros similares
```

### Revisar C√≥digo

```
Revise o c√≥digo abaixo como um engenheiro s√™nior:

[c√≥digo]

Avalie:
- Legibilidade
- Performance
- Seguran√ßa
- Manutenibilidade
- Padr√µes e boas pr√°ticas

Para cada ponto, d√™ nota (1-10) e sugest√£o de melhoria.
```

---

## Engenharia Autom√°tica de Prompts (APE)

Usa o pr√≥prio LLM para **gerar e otimizar prompts**.

**Processo:**

1. **Gera√ß√£o:** LLM cria N variantes do prompt
2. **Avalia√ß√£o:** Testa cada variante com m√©tricas (BLEU, ROUGE, accuracy)
3. **Sele√ß√£o:** Escolhe a melhor variante
4. **Refinamento:** Itera sobre a melhor

**Exemplo:**

```
Tarefa: Criar prompts para um chatbot de e-commerce que ajuda clientes a encontrar produtos.

Prompt de entrada: "Quero uma camisa azul"

Gere 10 variantes de como clientes podem formular esse pedido:
```

**Sa√≠da:**
1. "Estou procurando uma camisa na cor azul"
2. "Voc√™s t√™m camisas azuis?"
3. "Me mostra as op√ß√µes de camisa azul"
4. "Quero ver camisas masculinas azuis"
...

**Uso:** Treinar modelos, gerar datasets sint√©ticos, testar robustez.

---

## Melhores Pr√°ticas

### 1. ‚úÖ Forne√ßa Exemplos

**Recomenda√ß√£o:** 3-5 exemplos para few-shot

**Por que funciona:** Modelos aprendem por padr√£o. Exemplos mostram exatamente o que voc√™ espera.

---

### 2. ‚úÖ Design com Simplicidade

**Antes:**
> Estou visitando Nova York agora com meus dois filhos de 3 anos e gostaria de saber sobre √≥timos locais para visitar durante nossas f√©rias de ver√£o, considerando que as crian√ßas ficam cansadas facilmente.

**Depois:**
> Sugira 5 lugares em Nova York para visitar com crian√ßas de 3 anos. Prefira locais com ar-condicionado e tempo de visita curto (m√°x. 2h).

**Princ√≠pio:** Se est√° confuso para voc√™, est√° confuso para o modelo.

---

### 3. ‚úÖ Seja Espec√≠fico sobre a Sa√≠da

| ‚ùå Vago | ‚úÖ Espec√≠fico |
|---------|---------------|
| "Resuma o texto" | "Resuma em 3 bullet points de no m√°ximo 20 palavras cada" |
| "Classifique" | "Classifique como A, B ou C. Retorne apenas a letra." |
| "Explique" | "Explique em 2 par√°grafos para um p√∫blico leigo" |

---

### 4. ‚úÖ Use Instru√ß√µes Positivas

| ‚ùå Negativo | ‚úÖ Positivo |
|-------------|-------------|
| "N√£o use jarg√µes" | "Use linguagem simples e acess√≠vel" |
| "N√£o seja longo" | "Seja conciso (m√°x. 100 palavras)" |
| "N√£o invente" | "Responda apenas com informa√ß√µes do texto fornecido" |

---

### 5. ‚úÖ Use Delimitadores

Separe partes do prompt claramente:

```
Analise o texto abaixo:

---TEXTO---
[texto aqui]
---FIM DO TEXTO---

Identifique: tema principal, tom e p√∫blico-alvo.
```

**Delimitadores comuns:**
- `---` (tra√ßos)
- `"""` (aspas triplas)
- ``` ``` ``` (backticks)
- `###` (hashtags)
- Tags XML: `<texto>...</texto>`

---

### 6. ‚úÖ Use Vari√°veis

Torne prompts reutiliz√°veis:

```python
prompt_template = """
Voc√™ √© um {papel}.

Tarefa: {tarefa}
Contexto: {contexto}
Formato de sa√≠da: {formato}

Resposta:
"""
```

---

### 7. ‚úÖ Divida Tarefas Complexas

**Em vez de um prompt gigante:**

```
Analise este contrato, identifique riscos, sugira melhorias, 
calcule multas potenciais, compare com a legisla√ß√£o atual...
```

**Divida em etapas:**

```
Prompt 1: Extraia as cl√°usulas principais
Prompt 2: Analise cada cl√°usula quanto a riscos
Prompt 3: Sugira melhorias para cl√°usulas de risco
Prompt 4: Resuma os pontos cr√≠ticos
```

---

### 8. ‚úÖ Pe√ßa para o Modelo Verificar

Adicione auto-verifica√ß√£o:

```
[Instru√ß√£o principal]

Antes de responder, verifique:
1. A resposta est√° no formato solicitado?
2. Todas as partes da pergunta foram respondidas?
3. H√° contradi√ß√µes na resposta?

Se houver problemas, corrija antes de finalizar.
```

---

### 9. ‚úÖ Itere e Documente

**Template de documenta√ß√£o:**

| Vers√£o | Data | Prompt | Config | Resultado | Observa√ß√µes |
|--------|------|--------|--------|-----------|-------------|
| 1.0 | 24/02 | [texto] | temp=0.5 | 70% accuracy | Muitos falsos positivos |
| 1.1 | 24/02 | [texto] | temp=0.3 | 85% accuracy | Adicionei 2 exemplos |
| 1.2 | 25/02 | [texto] | temp=0.2 | 92% accuracy | Few-shot + CoT |

---

### 10. ‚úÖ Teste com Casos Extremos

**Edge cases para testar:**
- Entrada vazia
- Entrada muito longa
- Caracteres especiais
- Idiomas mistos
- Contradi√ß√µes no texto
- Informa√ß√µes amb√≠guas

---

### 11. ‚úÖ Controle Alucina√ß√µes

**T√©cnicas:**

```
# Apenas fatos do texto
"Responda apenas com informa√ß√µes explicitamente presentes no texto."

# Citar fonte
"Para cada afirma√ß√£o, cite a frase exata do texto que a embasa."

# Admitir ignor√¢ncia
"Se a informa√ß√£o n√£o estiver no texto, responda 'INFORMA√á√ÉO N√ÉO DISPON√çVEL'."
```

---

### 12. ‚úÖ Use Few-shot com Classes Balanceadas

**‚ùå Desbalanceado:**
```
Positivo: "√ìtimo produto!"
Positivo: "Adorei!"
Positivo: "Recomendo!"
Positivo: "Excelente!"
Negativo: "Horr√≠vel."
```

**‚úÖ Balanceado:**
```
Positivo: "√ìtimo produto!"
Negativo: "Horr√≠vel."
Positivo: "Adorei!"
Negativo: "N√£o recomendo."
Positivo: "Excelente!"
```

---

### 13. ‚úÖ Adapte-se ao Modelo

Cada modelo tem caracter√≠sticas diferentes:

| Modelo | Caracter√≠sticas | Dicas |
|--------|-----------------|-------|
| **GPT-4** | Racioc√≠nio forte, verbose | Pe√ßa concis√£o |
| **Claude** | Segue instru√ß√µes bem, menos verbose | √ìtimo para instru√ß√µes longas |
| **Gemini** | Multimodal, bom em c√≥digo | Aproveite imagens |
| **LLaMA** | Open source, mais limitado | Prompts mais simples |

---

### 14. ‚úÖ Teste Diferentes Formatos de Sa√≠da

| Formato | Quando Usar |
|---------|-------------|
| **JSON** | Integra√ß√£o com sistemas, APIs |
| **Markdown** | Documenta√ß√£o, relat√≥rios |
| **CSV** | Dados tabulares |
| **XML** | Sistemas legados |
| **YAML** | Configura√ß√µes |
| **Lista** | Leitura r√°pida |

---

### 15. ‚úÖ Use Chain-of-Thought com Modera√ß√£o

**Quando usar:**
- Problemas l√≥gicos/matem√°ticos
- An√°lise multi-passo
- Debugging

**Quando N√ÉO usar:**
- Classifica√ß√£o simples
- Respostas de uma palavra
- Quando custo de tokens importa

---

## Anti-Padr√µes ‚ö†Ô∏è (O Que Evitar)

### ‚ùå Prompts Vagos

```
"Fale sobre marketing"
```

**Problema:** Sem dire√ß√£o, sem escopo, sem formato.  
**Corre√ß√£o:** "Explique 5 estrat√©gias de marketing digital para pequenas empresas em 200 palavras."

---

### ‚ùå Instru√ß√µes Conflitantes

```
"Seja breve mas cubra todos os detalhes importantes do documento de 50 p√°ginas"
```

**Problema:** Imposs√≠vel satisfazer ambas as restri√ß√µes.  
**Corre√ß√£o:** "Resuma os 3 pontos mais importantes em 100 palavras."

---

### ‚ùå Ambiguidade

```
"O pr√™mio foi de 1000 reais. Quanto Jo√£o recebeu?"
```

**Problema:** N√£o diz quem √© Jo√£o ou como o pr√™mio foi dividido.  
**Corre√ß√£o:** "O pr√™mio de 1000 reais foi dividido igualmente entre Jo√£o e Maria. Quanto Jo√£o recebeu?"

---

### ‚ùå Sobrecarga de Instru√ß√µes

```
"Seja formal mas amig√°vel, use termos t√©cnicos mas explique para leigos, 
seja conciso mas detalhado, use humor mas seja profissional..."
```

**Problema:** Muitas restri√ß√µes conflitantes.  
**Corre√ß√£o:** Escolha 2-3 caracter√≠sticas principais.

---

### ‚ùå Assumir Conhecimento

```
"Use a metodologia XYZ para analisar isso."
```

**Problema:** O modelo pode n√£o conhecer ou ter defini√ß√£o diferente.  
**Corre√ß√£o:** "Use a metodologia XYZ (descrita abaixo)..." ou explique a metodologia.

---

### ‚ùå Exemplos Inconsistentes

```
EXEMPLO 1: Sa√≠da = "Positivo"
EXEMPLO 2: A resposta √©: Negativo
EXEMPLO 3: POSITIVO
```

**Problema:** Formatos diferentes confundem o modelo.  
**Corre√ß√£o:** Mantenha formato consistente em todos os exemplos.

---

## Checklist de Revis√£o de Prompt

Antes de usar um prompt em produ√ß√£o, verifique:

### Clareza
- [ ] A tarefa est√° claramente definida?
- [ ] N√£o h√° ambiguidades?
- [ ] O formato de sa√≠da est√° especificado?

### Contexto
- [ ] H√° contexto suficiente?
- [ ] O contexto √© relevante (sem ru√≠do)?
- [ ] H√° exemplos (se necess√°rio)?

### Restri√ß√µes
- [ ] H√° limite de tamanho?
- [ ] O formato est√° definido?
- [ ] H√° restri√ß√µes de tom/estilo?

### Testes
- [ ] Testei com entradas t√≠picas?
- [ ] Testei com edge cases?
- [ ] Testei m√∫ltiplas vezes (consist√™ncia)?

### T√©cnico
- [ ] A temperatura est√° apropriada?
- [ ] O limite de tokens est√° adequado?
- [ ] O modelo escolhido √© adequado para a tarefa?

---

## Templates Prontos para Usar

### üìù Resumo de Texto

```
Resuma o texto abaixo em {n} bullet points.

REGRAS:
- Cada bullet: m√°ximo {x} palavras
- Foque em informa√ß√µes factuais
- Mantenha linguagem neutra
- N√£o adicione informa√ß√µes externas

TEXTO:
{texto}

RESUMO:
```

---

### üè∑Ô∏è Classifica√ß√£o

```
Classifique o seguinte texto em uma das categorias: {categorias}

EXEMPLOS:
"{exemplo_1}" ‚Üí {classe_1}
"{exemplo_2}" ‚Üí {classe_2}

TEXTO:
"{texto}"

CATEGORIA:
```

---

### üîç Extra√ß√£o de Dados

```
Extraia as seguintes informa√ß√µes do texto:
- {campo_1}
- {campo_2}
- {campo_3}

Retorne em JSON:
{
  "{campo_1}": "...",
  "{campo_2}": "...",
  "{campo_3}": "..."
}

TEXTO:
{texto}

JSON:
```

---

### üíª Gera√ß√£o de C√≥digo

```
Escreva uma fun√ß√£o em {linguagem} que {descricao}.

REQUISITOS:
- {requisito_1}
- {requisito_2}
- Incluir docstring
- Incluir type hints
- Tratar erros

EXEMPLO DE USO:
{exemplo}

C√ìDIGO:
```

---

### üé≠ An√°lise com Papel

```
Voc√™ √© um {papel} com {anos} anos de experi√™ncia em {area}.

Analise o seguinte {tipo_conteudo}:

{conteudo}

Sua an√°lise deve cobrir:
1. {aspecto_1}
2. {aspecto_2}
3. {aspecto_3}

Forne√ßa cr√≠ticas construtivas e sugest√µes pr√°ticas.

AN√ÅLISE:
```

---

### üîÑ Tradu√ß√£o com Contexto

```
Traduza o texto de {idioma_origem} para {idioma_destino}.

CONTEXTO:
- P√∫blico: {publico}
- Tom: {tom}
- Prop√≥sito: {proposito}

TEXTO ORIGINAL:
{texto}

TRADU√á√ÉO:
```

---

## Troubleshooting Comum

### Problema: Respostas muito longas

**Solu√ß√µes:**
- Adicione "Seja conciso" ou "M√°ximo X palavras"
- Reduza max_tokens
- Pe√ßa bullet points em vez de par√°grafos

---

### Problema: Respostas muito curtas

**Solu√ß√µes:**
- Pe√ßa "Responda em detalhes"
- Aumente max_tokens
- Use "Explique seu racioc√≠nio"

---

### Problema: Formato inconsistente

**Solu√ß√µes:**
- Adicione exemplos few-shot
- Use delimitadores no formato esperado
- Seja mais espec√≠fico sobre a estrutura

---

### Problema: Alucina√ß√µes

**Solu√ß√µes:**
- "Responda apenas com informa√ß√µes do texto"
- "Se n√£o souber, diga 'N√£o sei'"
- Reduza temperatura
- Pe√ßa cita√ß√µes/fontes

---

### Problema: Loop de repeti√ß√£o

**Solu√ß√µes:**
- Ajuste temperatura (nem muito baixa nem muito alta)
- Reduza top-K
- Limite max_tokens
- Reformule o prompt

---

### Problema: Ignora instru√ß√µes

**Solu√ß√µes:**
- Coloque instru√ß√µes no in√≠cio
- Use prompt de sistema
- Seja mais expl√≠cito
- Use delimitadores para separar instru√ß√µes de conte√∫do

---

## Refer√™ncia R√°pida

### T√©cnicas por Tipo de Tarefa

| Tarefa | T√©cnicas Recomendadas |
|--------|----------------------|
| Classifica√ß√£o | Zero-shot, Few-shot, Sistema |
| Extra√ß√£o | Few-shot, JSON output |
| Resumo | Sistema, Contexto |
| Racioc√≠nio | CoT, Step-back |
| Criatividade | Papel, Temperatura alta |
| C√≥digo | Sistema, CoT, Few-shot |
| An√°lise | Papel, CoT, Step-back |
| Conversa√ß√£o | Sistema, Papel, Contexto |

---

### Configura√ß√µes por Tipo de Tarefa

| Tarefa | Temperatura | Top-P | Top-K |
|--------|-------------|-------|-------|
| Fatos/C√≥digo | 0 | 0.9 | 20 |
| Classifica√ß√£o | 0.1 | 0.9 | 20 |
| Resumo | 0.2 | 0.95 | 30 |
| Conversa√ß√£o | 0.5 | 0.95 | 40 |
| Criatividade | 0.8 | 0.99 | 50 |

---

### Frases M√°gicas

| Objetivo | Frase |
|----------|-------|
| Ativar CoT | "Vamos pensar passo a passo." |
| Evitar alucina√ß√£o | "Se n√£o estiver no texto, responda 'N√£o dispon√≠vel'." |
| Garantir formato | "Retorne APENAS o JSON, sem texto adicional." |
| Melhor racioc√≠nio | "Pense cuidadosamente antes de responder." |
| Auto-verifica√ß√£o | "Verifique sua resposta antes de finalizar." |

---

## Notas Finais

- **Engenharia de prompt √© iterativa** ‚Äî experimente, me√ßa, melhore
- **Conhe√ßa seu modelo** ‚Äî cada um tem caracter√≠sticas diferentes
- **Documente tudo** ‚Äî vers√µes, resultados, aprendizados
- **Teste extensivamente** ‚Äî casos normais e edge cases
- **Valide sempre** ‚Äî especialmente para c√≥digo e fatos cr√≠ticos

---

*Documento baseado no whitepaper "Prompt Engineering" de Lee Boonstra, Google, Fevereiro de 2025*  
*Vers√£o expandida e aprimorada com pr√°ticas adicionais*
